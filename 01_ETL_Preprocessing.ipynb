{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c356c651",
   "metadata": {},
   "source": [
    "# WESM Price Prediction - ETL/Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f480b3",
   "metadata": {},
   "source": [
    "## Setup and \"Loader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d6d0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "PATH_GWAP = \"./raw_data/GWAP/\"\n",
    "PATH_RTD = \"./raw_data/RTD_Regional/\"\n",
    "PATH_OUTAGES = \"./raw_data/Outages/\"\n",
    "\n",
    "# Connects extracted CSV files\n",
    "def load_and_concatenate_csvs(path):\n",
    "    files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    print(f\"File Count in {path}: {len(files)}\")\n",
    "\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "\n",
    "    concatenated_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    print(f\"Concatenated DataFrame Shape from {path}: {concatenated_df.shape}\")\n",
    "    \n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f9700",
   "metadata": {},
   "source": [
    "## GWAP Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb72ab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Count in ./raw_data/GWAP/: 59\n",
      "Concatenated DataFrame Shape from ./raw_data/GWAP/: (85019, 6)\n",
      "Final GWAP DataFrame Shape: (16992, 2)\n",
      "               datetime       GWAP\n",
      "366 2025-10-28 00:05:00  2800.5685\n",
      "371 2025-10-28 00:10:00  2985.7148\n",
      "314 2025-10-28 00:15:00  2899.6850\n",
      "377 2025-10-28 00:20:00  2992.3605\n",
      "416 2025-10-28 00:25:00  2949.7466\n"
     ]
    }
   ],
   "source": [
    "df_gwap = load_and_concatenate_csvs(PATH_GWAP)\n",
    "df_gwap = df_gwap[df_gwap[\"REGION_NAME\"] == \"CLUZ\"].copy()\n",
    "df_gwap[\"datetime\"] = pd.to_datetime(df_gwap[\"TIME_INTERVAL\"], format='mixed', dayfirst=False)\n",
    "df_gwap = df_gwap[[\"datetime\", \"GWAP\"]].sort_values(\"datetime\")\n",
    "df_gwap = df_gwap.drop_duplicates(subset=['datetime']) # just in case\n",
    "\n",
    "print(f\"Final GWAP DataFrame Shape: {df_gwap.shape}\")\n",
    "print(df_gwap.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09354c04",
   "metadata": {},
   "source": [
    "## RTD Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b0aee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Count in ./raw_data/RTD_Regional/: 59\n",
      "Concatenated DataFrame Shape from ./raw_data/RTD_Regional/: (254879, 13)\n",
      "Final RTD Features DataFrame Shape: (16988, 6)\n",
      "             datetime  energy_demand_mw  energy_supply_mw  reserve_demand_mw  \\\n",
      "0 2025-10-28 00:05:00           9043.68           9095.22             1495.0   \n",
      "1 2025-10-28 00:10:00           9002.76           9038.49             1495.0   \n",
      "2 2025-10-28 00:15:00           8975.73           9026.83             1495.0   \n",
      "3 2025-10-28 00:20:00           9027.64           9012.70             1495.0   \n",
      "4 2025-10-28 00:25:00           9003.70           9001.07             1495.0   \n",
      "\n",
      "   reserve_supply_mw  reserve_shortage_mw  \n",
      "0             1495.0                  0.0  \n",
      "1             1495.0                  0.0  \n",
      "2             1495.0                  0.0  \n",
      "3             1495.0                  0.0  \n",
      "4             1495.0                  0.0  \n"
     ]
    }
   ],
   "source": [
    "df_rtd = load_and_concatenate_csvs(PATH_RTD)\n",
    "df_rtd = df_rtd[df_rtd[\"REGION_NAME\"] == \"CLUZ\"].copy()\n",
    "df_rtd[\"datetime\"] = pd.to_datetime(df_rtd[\"TIME_INTERVAL\"], format='mixed', dayfirst=False)\n",
    "\n",
    "# Extract Energy (Demand & Supply)\n",
    "# Commodity Type \"En\" refers to energy\n",
    "df_energy = df_rtd[df_rtd[\"COMMODITY_TYPE\"] == \"En\"].copy()\n",
    "df_energy = df_energy[[\"datetime\", \"MKT_REQT\", \"GENERATION\"]]\n",
    "df_energy.columns = [\"datetime\", \"energy_demand_mw\", \"energy_supply_mw\"]\n",
    "\n",
    "# Extract Reserves (Safety Net)\n",
    "# Anything that is not \"En\" are reserves\n",
    "df_reserves = df_rtd[df_rtd[\"COMMODITY_TYPE\"] != \"En\"].copy()\n",
    "\n",
    "# Group reserves by datetime then sum them up\n",
    "df_reserves = df_reserves.groupby(\"datetime\")[[\"MKT_REQT\", \"GENERATION\"]].sum().reset_index()\n",
    "df_reserves.columns = [\"datetime\", \"reserve_demand_mw\", \"reserve_supply_mw\"]\n",
    "\n",
    "# Engineered Feature: Shortage (mostly for the classification task; honestly not sure yet if this will affect it but i'll leave in this column for now)\n",
    "# Positive Value = We are short (Danger). Negative Value = We have surplus (Safe).\n",
    "df_reserves['reserve_shortage_mw'] = df_reserves['reserve_demand_mw'] - df_reserves['reserve_supply_mw']\n",
    "# Merge them back\n",
    "df_X = pd.merge(df_energy, df_reserves, on=\"datetime\", how=\"left\")\n",
    "df_X = df_X.fillna(0)  # Fill NaNs with 0\n",
    "\n",
    "print(f\"Final RTD Features DataFrame Shape: {df_X.shape}\")\n",
    "print(df_X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263e73e8",
   "metadata": {},
   "source": [
    "## Outage Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ba7cb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Count in ./raw_data/Outages/: 59\n",
      "Concatenated DataFrame Shape from ./raw_data/Outages/: (256054, 7)\n",
      "Dropped 59 rows with missing Resource Name.\n",
      "Filtered for Luzon (Prefixes 01-03). Remaining rows: 83792\n",
      "Final Outages DataFrame Shape: (16988, 2)\n",
      "             datetime  outage_count\n",
      "0 2025-10-28 00:05:00             4\n",
      "1 2025-10-28 00:10:00             4\n",
      "2 2025-10-28 00:15:00             4\n",
      "3 2025-10-28 00:20:00             4\n",
      "4 2025-10-28 00:25:00             4\n"
     ]
    }
   ],
   "source": [
    "df_outages = load_and_concatenate_csvs(PATH_OUTAGES)\n",
    "\n",
    "# Drop rows with missing Resource Name\n",
    "initial_len = len(df_outages)\n",
    "df_outages = df_outages.dropna(subset=['RESOURCE_NAME'])\n",
    "print(f\"Dropped {initial_len - len(df_outages)} rows with missing Resource Name.\")\n",
    "\n",
    "# Filter to Luzon plants only (Prefix 01-03)\n",
    "df_outages['prefix'] = df_outages['RESOURCE_NAME'].astype(str).str[:2]\n",
    "luzon_prefixes = ['01', '02', '03']\n",
    "df_outages = df_outages[df_outages['prefix'].isin(luzon_prefixes)].copy()\n",
    "print(f\"Filtered for Luzon (Prefixes 01-03). Remaining rows: {len(df_outages)}\")\n",
    "\n",
    "df_outages['datetime'] = pd.to_datetime(df_outages['RUN_TIME'], format='mixed', dayfirst=False)\n",
    "df_out_count = df_outages.groupby('datetime').size().reset_index(name='outage_count') # count of outages per datetime\n",
    "\n",
    "print(f\"Final Outages DataFrame Shape: {df_out_count.shape}\")\n",
    "print(df_out_count.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902a3ef",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bf548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Shape: (16700, 11)\n",
      "Date Range: 2025-10-29 00:05:00 to 2025-12-26 00:00:00\n",
      "               datetime       GWAP  energy_demand_mw  energy_supply_mw  \\\n",
      "288 2025-10-29 00:05:00  2258.5866           9504.45           9705.25   \n",
      "289 2025-10-29 00:10:00  2913.4257           9483.49           9648.89   \n",
      "290 2025-10-29 00:15:00  2883.5764           9434.35           9627.98   \n",
      "291 2025-10-29 00:20:00  2888.6233           9417.62           9614.19   \n",
      "292 2025-10-29 00:25:00  2887.9553           9379.48           9575.17   \n",
      "\n",
      "     reserve_demand_mw  reserve_supply_mw  reserve_shortage_mw  outage_count  \\\n",
      "288             1428.0             1428.0                  0.0           4.0   \n",
      "289             1428.0             1428.0                  0.0           4.0   \n",
      "290             1428.0             1428.0                  0.0           4.0   \n",
      "291             1428.0             1428.0                  0.0           4.0   \n",
      "292             1428.0             1428.0                  0.0           4.0   \n",
      "\n",
      "     GWAP_Lag_1  GWAP_Lag_12  GWAP_Lag_288  \n",
      "288   2911.7934    2977.5806     2800.5685  \n",
      "289   2258.5866    3134.3441     2985.7148  \n",
      "290   2913.4257    3134.7814     2899.6850  \n",
      "291   2883.5764    3028.0328     2992.3605  \n",
      "292   2888.6233    3028.4820     2949.7466  \n"
     ]
    }
   ],
   "source": [
    "# Merge GWAP with RTD features\n",
    "final_df = pd.merge(df_gwap, df_X, on=\"datetime\", how=\"inner\")\n",
    "\n",
    "# Merge with Outages data\n",
    "final_df = pd.merge(final_df, df_out_count, on=\"datetime\", how=\"left\")\n",
    "final_df['outage_count'] = final_df['outage_count'].fillna(0)  # Fill NaNs with 0\n",
    "\n",
    "# Time Lags (for autocorrelation)\n",
    "final_df['GWAP_Lag_1'] = final_df['GWAP'].shift(1)    # 5 mins ago\n",
    "final_df['GWAP_Lag_12'] = final_df['GWAP'].shift(12)  # 1 hour ago\n",
    "final_df['GWAP_Lag_288'] = final_df['GWAP'].shift(288) # 24 hours ago (Yesterday same time)\n",
    "\n",
    "final_df = final_df.dropna()\n",
    "final_df.to_csv(\"final_dataset.csv\", index=False)\n",
    "\n",
    "print(f\"Final Dataset Shape: {final_df.shape}\")\n",
    "print(f\"Date Range: {final_df['datetime'].min()} to {final_df['datetime'].max()}\")\n",
    "print(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
